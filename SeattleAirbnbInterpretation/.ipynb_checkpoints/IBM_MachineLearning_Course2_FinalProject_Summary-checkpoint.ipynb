{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "955093da",
   "metadata": {},
   "source": [
    "# Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33209947",
   "metadata": {},
   "source": [
    "The goal of this machine learning project is to explore and interpret the Seattle Airbnb data rather than to make accurate predictions. While prediction is a common goal of machine learning projects, our focus will be on gaining insights into the data and understanding the relationships between different features. Specifically, we are interested in answering questions such as: what are the most important factors that affect Airbnb prices in Seattle? How do these factors interact with each other? \n",
    "By taking an interpretive approach, we hope to not only develop a better understanding of the Seattle Airbnb market but also to shed light on the broader issues of housing affordability and access to short-term rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca76a91",
   "metadata": {},
   "source": [
    "# Brief description of the data set you chose and a summary of its attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af018e",
   "metadata": {},
   "source": [
    "The Seattle Airbnb data set contains information about the listings and reviews\n",
    "of Airbnb in Seattle, Washington. It consists of three files: listings, calendar,\n",
    "and reviews.\n",
    "The listings file has 92 attributes, including property type, room type, neighbourhood,\n",
    "price, availability, number of reviews, and host information, the calendar\n",
    "file has information about the availability and price of each listing on a\n",
    "given data and the reviews file includes information about the guest reviews and\n",
    "ratings for each listing.\n",
    "The listing file was the most pertinent for the project, and therefore, the only\n",
    "file used for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e1213a",
   "metadata": {},
   "source": [
    "# Brief summary of data exploration and actions taken for data cleaning and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79667717",
   "metadata": {},
   "source": [
    "The initial plan for data exploration is to first gain a general understanding of\n",
    "the data, including the size of the data set, the number of missing values, and\n",
    "the distribution of the attributes. Then, I will perform univariate and bivariate\n",
    "analysis to explore the relationships between different attributes. I will also\n",
    "create visualizations, such as histograms, scatterplots, and heatmaps, to help\n",
    "identify patterns and correlations in the data.\n",
    "3 Actions taken for data cleaning and feature\n",
    "engineering\n",
    "\n",
    "*   **Dropping non relevant features**\n",
    "\n",
    "The following steps were taken for data cleaning and feature engineering:\n",
    "Firstly, non-numerical features and irrelevant ones were dropped, such as ’listing\n",
    "url’, ’source’, ’name’, ’description’, ’neighbourhood overview’, ’picture url’, ’host url’, etc.\n",
    "Secondly, features representing IDs, namely ’id’, ’scrape id’, and ’host id’, were\n",
    "dropped.\n",
    "Lastly, the ’bathrooms’ feature was dropped as it had no data and was empty.\n",
    "\n",
    "*   **Handling missing values**\n",
    "\n",
    "1 df. isnull (). sum (). sort_values ( ascending = False )\n",
    "Listing 1: Python code snippet for missing values\n",
    "Missing values were identified in certain features, namely ’review scores value’,\n",
    "’review scores location’, ’review scores accuracy’, ’review scores checkin’, ’review\n",
    "scores communication’, ’review scores cleanliness’, ’last review duration in days’,\n",
    "’first review duration in days’, ’reviews per month’, ’review scores rating’, ’bedrooms’,\n",
    "and ’beds’.\n",
    "The missing values in the review scores and bedrooms features were replaced\n",
    "with the median due to skewed data. For the ’beds’ feature, the 71 rows with\n",
    "missing values were removed.\n",
    "\n",
    "*   **Transforming data types**\n",
    "\n",
    "In this dataset, many features were of object type, so I performed several transformations\n",
    "For instance, I converted the features ’host is superhost’, ’host has profile pic’,\n",
    "’host identity verified’, ’has availability’, and ’instant bookable’ from string values\n",
    "of ”t” and ”f” to binary values of ”1” and ”0”, respectively.\n",
    "To transform the date features ’host since’, ’first review’, and ’last review’, I calculated\n",
    "the duration until the dataset was last scraped using the ’last scraped’\n",
    "feature.\n",
    "For the ’host location’ feature, which had 162 unique locations, I simplified it by\n",
    "keeping only the four most frequent locations [’Seattle, WA’, ’New York, NY’,\n",
    "’San Francisco, CA’, ’Bellevue, WA’] and creating an ’Others’ category for the\n",
    "remaining locations.\n",
    "Moreover, I removed any non-numeric signs such as ”%” or ”$” from the values\n",
    "of ’host response rate’, ’host acceptance rate’, and ’price’.\n",
    "Finally, I transformed the ’property type’ feature into three categories: ’wholeUnit’,\n",
    "’room’, and ’other’. The ’property type’ feature was then one-hot encoded,\n",
    "and the original feature was dropped from the dataset.\n",
    "\n",
    "*   **Encoding categorical variables**\n",
    "\n",
    "In the cleaning process of the Airbnb Seattle dataset, categorical features were\n",
    "encoded to numerical values to allow for better analysis and modeling.\n",
    "The ’host location’ column was filtered based on a list of preferred locations,\n",
    "and then one-hot encoded using Pandas’ get dummies function.\n",
    "The ’room type’ column was also one-hot encoded and the ’Shared room’ and\n",
    "’Hotel room’ categories were dropped.\n",
    "The ’property type’ column was transformed using a custom function and then\n",
    "one-hot encoded. The resulting encoded columns were concatenated with the\n",
    "original dataset and the original categorical columns were dropped.\n",
    "These encoding techniques allowed for a more comprehensive analysis of the\n",
    "dataset and enabled machine learning models to be trained on the data.\n",
    "\n",
    "*   **Creating new features from existing ones**\n",
    "\n",
    "In order to simplify the host verification feature, which had five possible values,\n",
    "including combinations of ’email’, ’phone’, and ’work email’, I transformed it\n",
    "into three separate features: host verifications phone, host verifications email,\n",
    "and host verificationsv work email. For each new feature, a value of 1 was assigned\n",
    "if the corresponding verification method was present, and 0 if it was not.\n",
    "The ’bathrooms text’ feature, which contained textual descriptions of bathrooms,\n",
    "was transformed into a numerical feature called ’bathrooms number’.\n",
    "The ’amenities’ feature was transformed by counting the number of amenities\n",
    "listed. The resulting value was stored in a new feature called ’amenities number’,\n",
    "and the original ’amenities’ column was then dropped using the ’drop’ method\n",
    "in pandas.\n",
    "A new feature was created in the Airbnb Seattle dataset called ’distance from city center’\n",
    "by calculating the distance between the latitude and longitude of each listing\n",
    "and the central point of the city using the Haversine formula.\n",
    "Finally, the original latitude and longitude columns were dropped from the\n",
    "dataset.\n",
    "\n",
    "*   **Removing outliers**\n",
    "\n",
    "To gain insights into the data and identify any potential outliers, a pairplot\n",
    "was created using Seaborn. By examining the resulting plots, outliers were\n",
    "identified and removed from the dataset. Additionally, to avoid any bias caused\n",
    "by extreme values, any prices greater than 1500 were filtered out using the code:\n",
    "1 df = df[df[’price ’] <= 1500]\n",
    "Listing 2: Python code snippet for missing values\n",
    "This step was taken to ensure that the analysis and model performance were\n",
    "not adversely affected by outliers in the data.\n",
    "\n",
    "*   **Transforming skewed data**\n",
    "\n",
    "I performed two important data transformations to improve the quality of the\n",
    "data and the performance of the models.\n",
    "Firstly, I applied a log transformation to skewed data using the numpy log1p\n",
    "function. The skewed features were identified by their skewness value, which\n",
    "was calculated using the pandas skew function. Non boolean features with a\n",
    "skewness value greater than 1 or less than -1 were transformed. This transformation\n",
    "helps to normalize the distribution of the data and improve the accuracy\n",
    "of linear models.\n",
    "Secondly, I applied a standard scaling to continuous data using the Standard-\n",
    "Scaler function from the Scikit-learn library. A list of continuous features was\n",
    "selected and scaled using the scaler.fit transform method. Scaling the data ensures\n",
    "that each feature has a similar range and mean, which is beneficial for\n",
    "models that rely on distance-based calculations, such as K-nearest neighbours\n",
    "and support vector machines.\n",
    "To verify the impact of the log transformation, I plotted the distribution of the\n",
    "’price’ feature using the seaborn distplot function before and after the transformation.\n",
    "The initial distribution was positively skewd with a value of 19.677297,\n",
    "which can make it difficult for models to accurately predict high-priced listings.\n",
    "After the log transformation, the distribution became more normal, with\n",
    "a skewness value of 0.309012.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f528c",
   "metadata": {},
   "source": [
    "# Summary of training at least three linear regression models which should be variations that cover using a simple linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c80500",
   "metadata": {},
   "source": [
    "1. **Simple Linear Regression:**\n",
    "\n",
    "In this model, we used a single independent variable to predict the dependent variable. As a baseline, we used the \"price\" column as the dependent variable and select a single numerical feature, such as \"accommodates\" (number of people the listing can accommodate), as the independent variable. \n",
    "\n",
    "We splitted the dataset into training and test sets, ensuring all models use the same splits or cross-validation method. \n",
    "We fit a linear regression model to the training data and evaluate its performance on the test set using appropriate metrics such as mean squared error MSE and R-squared.<\n",
    "\n",
    "2. **Polynomial Regression:**\n",
    "\n",
    "To capture non-linear relationships, we extended the simple linear regression model by adding polynomial effects. In this variation, we transformed the original features by creating polynomial features of a higher degree. \n",
    "We trained the polynomial regression model using the same training and test splits and cross-validation method as the previous model and evaluate its performance.\n",
    "\n",
    "3. **Regularized Regression Lasso:**\n",
    "\n",
    "To prioritize interpretation over prediction, we can choose Lasso regression as our regularization technique. Lasso regression performs both regularization and feature selection by driving the coefficients of irrelevant features to zero. By shrinking or eliminating certain coefficients, Lasso regression helps identify the most important variables for predicting the dependent variable.\n",
    "\n",
    "Using Lasso regression, we can gain insights into which independent variables have the most impact on the price of Airbnb listings in Seattle. The coefficients of the non-zero features in the Lasso model can provide valuable information about the relative importance and direction of these variables. This can aid in interpreting the factors that contribute significantly to the pricing of listings, such as location, amenities, or property characteristics.\n",
    "We also preprocessed the data by handling missing values, encoding categorical variables, and normalizing or standardizing numerical features. Additionally, feature selection techniques like correlation analysis or stepwise regression were employed to identify the most relevant features for each model.\n",
    "\n",
    "By training these three variations of linear regression models on the Seattle Airbnb dataset and evaluating their performance using the same training and test splits or cross-validation method, we can gain insights into which model performs best for interpreting the dataset and predicting the prices of Airbnb listings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673f395",
   "metadata": {},
   "source": [
    "# A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d289b",
   "metadata": {},
   "source": [
    "Based on the coefficients obtained from the Lasso regression model, we can recommend it as the final model that best fits our needs in terms of accuracy and explainability for the Seattle Airbnb dataset.\n",
    "\n",
    "The Lasso model provides a balance between accuracy and interpretability. It performs feature selection by shrinking the coefficients of irrelevant variables to zero, allowing us to focus on the most important predictors. In this case, the coefficients of the Lasso model reveal the impact of various features on the price of Airbnb listings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7b5ad",
   "metadata": {},
   "source": [
    "# Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1adee2",
   "metadata": {},
   "source": [
    "From the coefficients, we observe that several variables play a significant role in determining the price. For example, the variable **\"room_type_Entire home/apt\"** has a coefficient of 0.693, indicating that it has a strong positive effect on the price. This suggests that entire homes or apartments tend to command higher prices compared to other room types.\n",
    "\n",
    "Additionally, the variables **\"host_is_superhost,\" \"host_listings_count,\" and \"instant_bookable\"** also have non-zero coefficients, suggesting they contribute positively to the price. On the other hand, variables such as **\"host_has_profile_pic,\" \"host_identity_verified,\" and \"has_availability\"** have coefficients close to zero, indicating they have negligible influence on the price.\n",
    "\n",
    "Furthermore, certain variables like **\"minimum_nights,\" \"number_of_reviews,\" and \"distance_from_city_center\"** have negative coefficients, suggesting a negative impact on the price. This implies that longer minimum stay requirements, higher numbers of reviews, and being located farther from the city center may lead to lower listing prices.\n",
    "Overall, the Lasso regression model provides a clear and interpretable understanding of how different features contribute to the pricing of Seattle Airbnb listings. It allows us to focus on the most influential variables while filtering out less significant ones, making it a suitable choice for both accuracy and explainability in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea129e45",
   "metadata": {},
   "source": [
    "# Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model adding specific data features to achieve a better explanation or a better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e2aec",
   "metadata": {},
   "source": [
    "In order to achieve a better explanation and prediction for the Seattle Airbnb dataset, there are several next steps to consider. \n",
    "\n",
    "Firstly, it may be beneficial to revisit the current model and explore the addition of specific data features that could provide more meaningful insights into pricing. This could involve conducting further feature engineering, extracting new variables, or incorporating domain-specific information such as local events or proximity to amenities. By enriching the dataset with relevant features, we can improve the model's explanatory power.\n",
    "\n",
    "Additionally, since regression models, such as the Lasso regression used, may not always be the best choice for prediction, it is worth exploring alternative machine learning models.\n",
    "\n",
    "By incorporating these suggestions, we can deepen our analysis of the Seattle Airbnb dataset. By revisiting the current model and adding specific data features, we can enhance the model's explanatory capabilities. Furthermore, exploring alternative machine learning models allows us to leverage more advanced techniques that may better capture the complex patterns and relationships within the data, leading to improved prediction performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
